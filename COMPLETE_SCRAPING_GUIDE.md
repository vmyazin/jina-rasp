# Complete Insurance Broker Scraping & Testing Guide

This guide covers the comprehensive scraping and testing pipeline for the Insurance Broker Directory project.

## ðŸš€ Quick Start - Complete Pipeline

Run the entire scraping and testing pipeline with one command:

```bash
# Run complete pipeline (no limit)
npm run scrape:complete

# Run with result limits (faster for testing)
npm run scrape:complete:10   # Limit to 10 brokers
npm run scrape:complete:25   # Limit to 25 brokers
npm run scrape:complete:50   # Limit to 50 brokers

# Custom limit
node scripts/complete-scrape-and-test.js --limit 15
```

This command will:

1. âœ… **Enhanced Jina AI Scraping** - Exhaustive research of insurance brokers
2. âœ… **Data Validation & Consolidation** - Clean and validate all data
3. âœ… **Database Update** - Insert clean data with security policies
4. âœ… **Comprehensive Playwright Testing** - Test ALL links and functionality
5. âœ… **Quality Assurance Report** - Generate detailed results

## ðŸ” Enhanced Jina AI Scraping

### What Makes It "Enhanced"

Our enhanced scraper performs **exhaustive research** using Jina AI APIs:

#### ðŸ”Ž **Search Phase (s.jina.ai)**

- **20+ comprehensive search queries** in Portuguese and English
- **Neighborhood-specific searches** (Centro, Aldeota, Meireles, etc.)
- **Company-specific searches** (Porto Seguro, Bradesco, SulAmÃ©rica, etc.)
- **Service-specific searches** (auto, vida, residencial, empresarial)

#### ðŸ“„ **Scraping Phase (r.jina.ai)**

- **Target URL scraping** from industry directories
- **Individual broker website scraping** for complete information
- **Automatic retry mechanism** for failed scrapes (3 attempts)
- **Rate limiting** to respect API limits

#### ðŸ”¬ **Deep Research Phase**

For each broker found, the scraper:

- âœ… **Scrapes their complete website** using r.jina.ai
- âœ… **Searches for additional mentions** across the web
- âœ… **Extracts comprehensive contact information**
- âœ… **Finds services, certifications, business hours**
- âœ… **Analyzes online presence** and credibility
- âœ… **Assigns confidence scores** based on data quality

### Enhanced Scraper Features

```bash
# Run enhanced scraper independently
npm run scrape:enhanced

# Run individual agents with limits
npm run scrape:agent1        # No limit
npm run scrape:agent1:10     # Limit to 10 brokers
node scripts/data/agent1_scraper.js --limit 5  # Custom limit
```

**What it extracts for each broker:**

- ðŸ“ž **Multiple phone numbers** (office, mobile, WhatsApp)
- ðŸ“§ **All email addresses** found
- ðŸ“ **Complete addresses** with neighborhood detection
- ðŸ¢ **Company information** (founded year, employees, branches)
- ðŸŽ¯ **Specialties** (auto, vida, residencial, empresarial, saÃºde)
- â­ **Services offered** (cotaÃ§Ã£o, consultoria, sinistros)
- ðŸ•’ **Business hours** extraction
- ðŸ“± **Social media profiles** (Instagram, Facebook, WhatsApp)
- ðŸ† **Certifications** (SUSEP, FENACOR)
- ðŸŒ **Online presence analysis**
- ðŸ“Š **Confidence scoring** (0-100%)

## ðŸ“Š Data Quality & Validation

The pipeline includes comprehensive data validation:

### âœ… **Validation Steps**

1. **Required Field Validation** - Ensures name, phone, email present
2. **Phone Number Standardization** - Formats to `(85) 99999-9999`
3. **Email Normalization** - Lowercase, format validation
4. **Duplicate Detection** - Removes identical records
5. **Address Standardization** - Consistent formatting
6. **Specialty Validation** - Ensures valid categories

### ðŸ“ˆ **Quality Metrics**

- **Success Rate**: Typically 80-90% of scraped data passes validation
- **Auto-Cleaning**: Phone/email formatting applied automatically
- **Duplicate Removal**: Intelligent matching prevents duplicates
- **Confidence Scoring**: Each broker gets 0-100% confidence score

## ðŸŽ­ Comprehensive Playwright Testing

After data collection, the pipeline runs extensive testing:

### ðŸ”— **Link Validation Tests**

```bash
# Test ALL links independently
npm run test:links:all
```

**What gets tested:**

- âœ… **Navigation links** (header/menu)
- âœ… **Footer links** (all footer sections)
- âœ… **Content links** (main page content)
- âœ… **Broker profile links** (external websites)
- âœ… **Internal links** (site navigation)
- âœ… **Protocol links** (mailto/tel validation)

### âš™ï¸ **Functionality Tests**

```bash
# Test core functionality
npm run test:functionality
```

**What gets tested:**

- âœ… **Page loading** and title validation
- âœ… **Search functionality** with real queries
- âœ… **Filter functionality** (neighborhood, specialty)
- âœ… **Mobile responsiveness** (375px viewport)
- âœ… **API endpoints** (/api/search, /api/filters, /api/health)
- âœ… **Error handling** (graceful failures)

### ðŸŒ **Multi-Browser Testing**

Tests run automatically on:

- **Desktop Chrome** (primary)
- **Desktop Firefox**
- **Desktop Safari**
- **Mobile Chrome** (Pixel 5)
- **Mobile Safari** (iPhone 12)

## ðŸ“‹ Pipeline Results & Reports

### ðŸ“Š **Execution Report**

After completion, you'll find detailed reports in:

- `reports/pipeline-report.json` - Complete execution details
- `reports/pipeline-summary.md` - Human-readable summary
- `playwright-report/` - Interactive test results
- `test-results/` - Screenshots and traces

### ðŸ“ˆ **Typical Results**

```
ðŸŽ¯ Pipeline Results:
â”œâ”€â”€ Scraping: âœ… SUCCESS (100+ brokers collected)
â”œâ”€â”€ Validation: âœ… SUCCESS (85% valid records)
â”œâ”€â”€ Database: âœ… SUCCESS (100 records inserted)
â””â”€â”€ Testing: âœ… SUCCESS (45/45 tests passed)

ðŸ“Š Summary Statistics:
â”œâ”€â”€ Total Execution Time: 180 seconds
â”œâ”€â”€ Success Rate: 100%
â”œâ”€â”€ Final Broker Count: 100
â””â”€â”€ Quality Assurance: All links validated
```

## ðŸ”§ Manual Operations

### Individual Components

```bash
# Run just the enhanced scraper
npm run scrape:enhanced

# Run individual agents with limits
npm run scrape:agent1:10     # Agent 1 with 10 broker limit
node scripts/data/agent1_scraper.js --limit 5  # Custom limit

# Run just data consolidation
npm run data:consolidate

# Run just database setup
npm run data:setup

# Run just link testing
npm run test:links:all

# View test reports
npm run test:report
```

### ðŸ”¢ **Result Limiting Options**

Control the number of brokers scraped for faster testing:

```bash
# Quick testing (10 brokers)
npm run scrape:complete:10

# Medium testing (25 brokers)
npm run scrape:complete:25

# Larger sample (50 brokers)
npm run scrape:complete:50

# Custom limits
node scripts/complete-scrape-and-test.js --limit 15
node scripts/data/agent1_scraper.js --limit 5

# No limit (find all available brokers)
npm run scrape:complete
```

**Benefits of using limits:**

- âš¡ **Faster execution** for testing and development
- ðŸ’° **Reduced API costs** (fewer Jina AI calls)
- ðŸŽ¯ **Focused testing** with manageable datasets
- ðŸ”„ **Quicker iteration** during development

### Debugging & Troubleshooting

```bash
# Run tests in headed mode (see browser)
npm run test:headed

# Run tests with UI (interactive)
npm run test:ui

# Debug specific test
npx playwright test --debug tests/comprehensive-link-check.spec.js
```

## ðŸŽ¯ Quality Assurance Standards

### âœ… **Data Quality Requirements**

- **Minimum 80% validation success rate**
- **All phone numbers in standard format**
- **No duplicate records in final database**
- **All addresses include Fortaleza, CE**
- **Confidence scores calculated for reliability**

### âœ… **Link Quality Requirements**

- **100% of navigation links must work**
- **100% of footer links must work**
- **External broker websites checked (with warnings for failures)**
- **All internal links must return valid pages**
- **No 404 errors allowed in production**

### âœ… **Testing Requirements**

- **All Playwright tests must pass before deployment**
- **Multi-browser compatibility verified**
- **Mobile responsiveness confirmed**
- **API endpoints functioning correctly**
- **Error handling working properly**

## ðŸš€ Deployment Workflow

### Recommended Process

```bash
# 1. Run complete pipeline
npm run scrape:complete

# 2. Review results
cat reports/pipeline-summary.md

# 3. Check for any issues
npm run test:report

# 4. Deploy only if all tests pass
# (Your deployment command here)
```

### Pre-Deployment Checklist

- [ ] Complete pipeline executed successfully
- [ ] All Playwright tests passing
- [ ] No broken links found
- [ ] Data validation success rate > 80%
- [ ] Database updated with clean data
- [ ] Security policies applied and tested

## ðŸ“š Additional Resources

- **Playwright Testing Guide**: `PLAYWRIGHT_TESTING.md`
- **Data Quality Dashboard**: `DATA_QUALITY_DASHBOARD.md`
- **Development Plan**: `DEVELOPMENT_PLAN.md`
- **Security Checklist**: `SECURITY_CHECKLIST.md`

## ðŸ†˜ Support & Troubleshooting

### Common Issues

**1. Jina API Rate Limiting**

- The scraper includes automatic delays and retry logic
- If you hit limits, wait 1 hour and retry

**2. Playwright Tests Failing**

- Check if server is running on port 2999
- Ensure all dependencies installed: `npm install`
- Try running tests in headed mode: `npm run test:headed`

**3. Database Connection Issues**

- Verify `.env` file has correct Supabase credentials
- Check if service role key is properly configured
- Run `npm run security:test-rls` to verify connection

**4. Link Validation Failures**

- External broker websites may be temporarily down (warnings only)
- Internal link failures indicate real issues that need fixing
- Check `playwright-report/` for detailed failure information

---

_This comprehensive pipeline ensures professional-quality data collection and testing for the Insurance Broker Directory._
